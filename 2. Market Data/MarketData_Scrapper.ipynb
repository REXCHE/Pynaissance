{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MarketData_Scrapper.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7jN7aZKiQ0UKZEAgAS1a9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conquerv0/Pynaissance/blob/master/2.%20Market%20Data/MarketData_Scrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tim6S7vgbTar",
        "colab_type": "text"
      },
      "source": [
        "# Obtaining Market Data through Algorithms\n",
        "\n",
        " Author: Victor Xiao\n",
        "\n",
        "Every algorithm-driven trading practices, deep quatitative analytic built upon consistency, interpretability and robustness of the data. In this notebook, the basic method of market data extraction is explored. In particular, yahoo finance is employed for market price data extraction. Note that this differ from advanced techinique that mines high-frequency data such as limit order book. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzpquzhaeHLa",
        "colab_type": "text"
      },
      "source": [
        "First, we need to set up the libraries and style."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5krjR5g2bXOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic Imports\n",
        "import bs4 as bs\n",
        "import matplot.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "import pickle\n",
        "import request\n",
        "import datetime as dt\n",
        "import os\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "\n",
        "style.use('ggplot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipRNAi9weSdX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**I. Market Data**\n",
        "\n",
        "Scrapping market data from yahoo and compile it into one dataframe.\n",
        "Some information about beautiful soup: To be updated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmdTTYb3ed6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sp500_tickers():\n",
        "  \"\"\"This function returns all the stock tickers listed on S&P500.\"\"\"\n",
        "  resp = request.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
        "  soup = bs.BeautifulSoup(resp.text)\n",
        "  table = soup.find('table', {'class': 'wikitable sortable'})\n",
        "  tickers = []\n",
        "  \n",
        "  for row in table.findAll('tr')[1:]:\n",
        "    ticker = row.findAll('td')[0].text\n",
        "    tickers.append(ticker)\n",
        "    \n",
        "  with open('sp500tickers.pickle', 'wb') as f:\n",
        "    pickle.dump(tickers, f)\n",
        "     \n",
        "  print(tickers)\n",
        "    \n",
        "  return tickers\n",
        "\n",
        "def get_yahoo_data(reload_sp500=False):\n",
        "  \"\"\"This function parses all data of the S&P500 to csv file from Yahoo. \"\"\"\n",
        "  if reload_sp500:\n",
        "    tickers = sp500_tickers()\n",
        "  else:\n",
        "    with open('sp500tickers.pickle', 'rb') as f:\n",
        "      tickers = pickle.load(f)\n",
        "  \n",
        "  if not os.path.exists('stock_dfs'):\n",
        "    os.makedirs('stock_dfs')\n",
        "  \n",
        "  start = dt.datetime(2008, 1, 1)\n",
        "  end = dt.datetime(2019, 12, 31)\n",
        "  \n",
        "  for ticker in tickers:\n",
        "    if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
        "      df = web.DataReader(ticker, 'yahoo', start, end)\n",
        "      df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
        "    else:\n",
        "      print('Always have {}'.format(ticker))\n",
        "      \n",
        " get_yahoo_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9vofrvPefm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_data():\n",
        "  \"This function parse csv files into pandas dataframes. \"\n",
        "  with open('sp500tickers.pickle', 'rb') as f:\n",
        "    tickers = pcikle.load(f)\n",
        "   \n",
        "  main_df = pd.DataFrame()\n",
        "  \n",
        "  for count, ticker in enumerate(tickers):\n",
        "    df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
        "    df.set_index('Date', inplace = True)\n",
        "    \n",
        "    df.rename(columns = {'Adj Close', ticker}, inplace=True)\n",
        "    df.drop(['Open', 'High', 'Low', 'Close', 'Volume'], 1, inplace=True)\n",
        "    \n",
        "    if main_df.empty:\n",
        "      main_df = df\n",
        "    else:\n",
        "      main_df = main_df.join(df, how='outer')\n",
        "    \n",
        "    if count % 10 == 0:\n",
        "      print(count)\n",
        "    \n",
        "  print(main_df.head())\n",
        "  main_df.to_csv('sp500_closes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg2qK9ivepgC",
        "colab_type": "text"
      },
      "source": [
        "**II. Data Visualization with correlation heat map**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWZ7K6uVeiYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize_data():\n",
        "  \"\"\"\"\"\"\n",
        "  df = pd.read_csv('sp500_joined_closes.csv')\n",
        "  df_corr = df.corr()\n",
        "  \n",
        "  data = df_corr.values\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(1, 1, 1) # An one by one plot.\n",
        "  \n",
        "  heatmap = ax.pcolor(data, cmap = plt.cm.RdYlGn)\n",
        "  fig.colorbar(heatmap)\n",
        "  ax.set_xticks(np.arange(data.shape[0])+ 0.5, minor=False)\n",
        "  ax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)\n",
        "  ax.inverst_yaxis()\n",
        "  ax.xaxis.tick_top()\n",
        "  \n",
        "  column_labels = df_corr.columns\n",
        "  row_labels = df_corr.index\n",
        "  \n",
        "  ax.set_xticklables(column_labels)\n",
        "  ax.set_yticklabels(row_labels)\n",
        "  plt.xticks(rotation=90)\n",
        "  heatmap.set_clim(-1, 1)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "  \n",
        "visualize_data()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}